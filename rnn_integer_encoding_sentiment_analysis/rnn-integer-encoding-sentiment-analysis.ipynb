{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-18T17:48:01.766581Z","iopub.execute_input":"2024-08-18T17:48:01.766974Z","iopub.status.idle":"2024-08-18T17:48:02.802406Z","shell.execute_reply.started":"2024-08-18T17:48:01.766939Z","shell.execute_reply":"2024-08-18T17:48:02.801326Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Recurrent Neural Network Sentiment Analysis using integer encoding technique\n# First the method is implemented in general and then applied on the imdb dataset\n# Author: Muhammad Humayun Khan\n\n# create own sentences\ndocs = [\n    'sun rises every morning',\n    'waves crash on shore',\n    'trees sway in wind',\n    'stars twinkle at night',\n    'birds chirp at dawn',\n    'rain falls on leaves',\n    'snow blankets the ground',\n    'fire crackles in fireplace',\n    'wind whispers through trees',\n    'clouds drift across sky'\n]","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:10:02.387173Z","iopub.execute_input":"2024-08-18T18:10:02.388349Z","iopub.status.idle":"2024-08-18T18:10:02.393410Z","shell.execute_reply.started":"2024-08-18T18:10:02.388310Z","shell.execute_reply":"2024-08-18T18:10:02.392201Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# now tokenize the sentence means word by word\nfrom tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(oov_token='<nothing>')\n\n# the oov_token means that replace the new word or out of dictionary word with nothing","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:15:29.979340Z","iopub.execute_input":"2024-08-18T18:15:29.979757Z","iopub.status.idle":"2024-08-18T18:15:29.985253Z","shell.execute_reply.started":"2024-08-18T18:15:29.979714Z","shell.execute_reply":"2024-08-18T18:15:29.983880Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# pass the data to be tokenize\ntokenizer.fit_on_texts(docs)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:16:27.572694Z","iopub.execute_input":"2024-08-18T18:16:27.573717Z","iopub.status.idle":"2024-08-18T18:16:27.578899Z","shell.execute_reply.started":"2024-08-18T18:16:27.573678Z","shell.execute_reply":"2024-08-18T18:16:27.577575Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer.word_index\n# unique word index\n# Words that appear more frequently are assigned lower indices (by default), while less frequent words get higher indices.","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:16:42.655436Z","iopub.execute_input":"2024-08-18T18:16:42.655826Z","iopub.status.idle":"2024-08-18T18:16:42.665155Z","shell.execute_reply.started":"2024-08-18T18:16:42.655794Z","shell.execute_reply":"2024-08-18T18:16:42.663872Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'<nothing>': 1,\n 'on': 2,\n 'trees': 3,\n 'in': 4,\n 'wind': 5,\n 'at': 6,\n 'sun': 7,\n 'rises': 8,\n 'every': 9,\n 'morning': 10,\n 'waves': 11,\n 'crash': 12,\n 'shore': 13,\n 'sway': 14,\n 'stars': 15,\n 'twinkle': 16,\n 'night': 17,\n 'birds': 18,\n 'chirp': 19,\n 'dawn': 20,\n 'rain': 21,\n 'falls': 22,\n 'leaves': 23,\n 'snow': 24,\n 'blankets': 25,\n 'the': 26,\n 'ground': 27,\n 'fire': 28,\n 'crackles': 29,\n 'fireplace': 30,\n 'whispers': 31,\n 'through': 32,\n 'clouds': 33,\n 'drift': 34,\n 'across': 35,\n 'sky': 36}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.word_counts\n# word repeatetion rate","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:17:02.358971Z","iopub.execute_input":"2024-08-18T18:17:02.359883Z","iopub.status.idle":"2024-08-18T18:17:02.367765Z","shell.execute_reply.started":"2024-08-18T18:17:02.359845Z","shell.execute_reply":"2024-08-18T18:17:02.366737Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"OrderedDict([('sun', 1),\n             ('rises', 1),\n             ('every', 1),\n             ('morning', 1),\n             ('waves', 1),\n             ('crash', 1),\n             ('on', 2),\n             ('shore', 1),\n             ('trees', 2),\n             ('sway', 1),\n             ('in', 2),\n             ('wind', 2),\n             ('stars', 1),\n             ('twinkle', 1),\n             ('at', 2),\n             ('night', 1),\n             ('birds', 1),\n             ('chirp', 1),\n             ('dawn', 1),\n             ('rain', 1),\n             ('falls', 1),\n             ('leaves', 1),\n             ('snow', 1),\n             ('blankets', 1),\n             ('the', 1),\n             ('ground', 1),\n             ('fire', 1),\n             ('crackles', 1),\n             ('fireplace', 1),\n             ('whispers', 1),\n             ('through', 1),\n             ('clouds', 1),\n             ('drift', 1),\n             ('across', 1),\n             ('sky', 1)])"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.document_count","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:17:40.667344Z","iopub.execute_input":"2024-08-18T18:17:40.667902Z","iopub.status.idle":"2024-08-18T18:17:40.675650Z","shell.execute_reply.started":"2024-08-18T18:17:40.667856Z","shell.execute_reply":"2024-08-18T18:17:40.674278Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"10"},"metadata":{}}]},{"cell_type":"code","source":"# create sequences for the words e.g. sun = 7 index, rise = 8 so all words will be combine\nsequences = tokenizer.texts_to_sequences(docs)\nsequences","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:17:52.813415Z","iopub.execute_input":"2024-08-18T18:17:52.814317Z","iopub.status.idle":"2024-08-18T18:17:52.821313Z","shell.execute_reply.started":"2024-08-18T18:17:52.814281Z","shell.execute_reply":"2024-08-18T18:17:52.820218Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[[7, 8, 9, 10],\n [11, 12, 2, 13],\n [3, 14, 4, 5],\n [15, 16, 6, 17],\n [18, 19, 6, 20],\n [21, 22, 2, 23],\n [24, 25, 26, 27],\n [28, 29, 4, 30],\n [5, 31, 32, 3],\n [33, 34, 35, 36]]"},"metadata":{}}]},{"cell_type":"code","source":"# start padding for equality of the words\nfrom keras.utils import pad_sequences","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:23:53.141967Z","iopub.execute_input":"2024-08-18T18:23:53.142396Z","iopub.status.idle":"2024-08-18T18:23:53.148286Z","shell.execute_reply.started":"2024-08-18T18:23:53.142364Z","shell.execute_reply":"2024-08-18T18:23:53.147236Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"sequences = pad_sequences(sequences,padding='post')\nsequences\n\n# till this point, our input data is prepared","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:24:06.380073Z","iopub.execute_input":"2024-08-18T18:24:06.380446Z","iopub.status.idle":"2024-08-18T18:24:06.387799Z","shell.execute_reply.started":"2024-08-18T18:24:06.380417Z","shell.execute_reply":"2024-08-18T18:24:06.386785Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([[ 7,  8,  9, 10],\n       [11, 12,  2, 13],\n       [ 3, 14,  4,  5],\n       [15, 16,  6, 17],\n       [18, 19,  6, 20],\n       [21, 22,  2, 23],\n       [24, 25, 26, 27],\n       [28, 29,  4, 30],\n       [ 5, 31, 32,  3],\n       [33, 34, 35, 36]], dtype=int32)"},"metadata":{}}]},{"cell_type":"markdown","source":"# **Implementation of the Integer Encoding Technique on the Real World Dataset IMDB**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,SimpleRNN,Flatten,Input","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:17.500857Z","iopub.execute_input":"2024-08-18T18:37:17.501260Z","iopub.status.idle":"2024-08-18T18:37:17.506780Z","shell.execute_reply.started":"2024-08-18T18:37:17.501230Z","shell.execute_reply":"2024-08-18T18:37:17.505538Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# load the data from the imdb dataset\n(X_train,y_train),(X_test,y_test) = imdb.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:32.850026Z","iopub.execute_input":"2024-08-18T18:37:32.850418Z","iopub.status.idle":"2024-08-18T18:37:38.033608Z","shell.execute_reply.started":"2024-08-18T18:37:32.850389Z","shell.execute_reply":"2024-08-18T18:37:38.032402Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"X_train[0]\n# the dataset is preprocessed and is ready. Can be checked below","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:38.047720Z","iopub.execute_input":"2024-08-18T18:37:38.048072Z","iopub.status.idle":"2024-08-18T18:37:38.066905Z","shell.execute_reply.started":"2024-08-18T18:37:38.048044Z","shell.execute_reply":"2024-08-18T18:37:38.065762Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[1,\n 14,\n 22,\n 16,\n 43,\n 530,\n 973,\n 1622,\n 1385,\n 65,\n 458,\n 4468,\n 66,\n 3941,\n 4,\n 173,\n 36,\n 256,\n 5,\n 25,\n 100,\n 43,\n 838,\n 112,\n 50,\n 670,\n 22665,\n 9,\n 35,\n 480,\n 284,\n 5,\n 150,\n 4,\n 172,\n 112,\n 167,\n 21631,\n 336,\n 385,\n 39,\n 4,\n 172,\n 4536,\n 1111,\n 17,\n 546,\n 38,\n 13,\n 447,\n 4,\n 192,\n 50,\n 16,\n 6,\n 147,\n 2025,\n 19,\n 14,\n 22,\n 4,\n 1920,\n 4613,\n 469,\n 4,\n 22,\n 71,\n 87,\n 12,\n 16,\n 43,\n 530,\n 38,\n 76,\n 15,\n 13,\n 1247,\n 4,\n 22,\n 17,\n 515,\n 17,\n 12,\n 16,\n 626,\n 18,\n 19193,\n 5,\n 62,\n 386,\n 12,\n 8,\n 316,\n 8,\n 106,\n 5,\n 4,\n 2223,\n 5244,\n 16,\n 480,\n 66,\n 3785,\n 33,\n 4,\n 130,\n 12,\n 16,\n 38,\n 619,\n 5,\n 25,\n 124,\n 51,\n 36,\n 135,\n 48,\n 25,\n 1415,\n 33,\n 6,\n 22,\n 12,\n 215,\n 28,\n 77,\n 52,\n 5,\n 14,\n 407,\n 16,\n 82,\n 10311,\n 8,\n 4,\n 107,\n 117,\n 5952,\n 15,\n 256,\n 4,\n 31050,\n 7,\n 3766,\n 5,\n 723,\n 36,\n 71,\n 43,\n 530,\n 476,\n 26,\n 400,\n 317,\n 46,\n 7,\n 4,\n 12118,\n 1029,\n 13,\n 104,\n 88,\n 4,\n 381,\n 15,\n 297,\n 98,\n 32,\n 2071,\n 56,\n 26,\n 141,\n 6,\n 194,\n 7486,\n 18,\n 4,\n 226,\n 22,\n 21,\n 134,\n 476,\n 26,\n 480,\n 5,\n 144,\n 30,\n 5535,\n 18,\n 51,\n 36,\n 28,\n 224,\n 92,\n 25,\n 104,\n 4,\n 226,\n 65,\n 16,\n 38,\n 1334,\n 88,\n 12,\n 16,\n 283,\n 5,\n 16,\n 4472,\n 113,\n 103,\n 32,\n 15,\n 16,\n 5345,\n 19,\n 178,\n 32]"},"metadata":{}}]},{"cell_type":"code","source":"# as can see above, the sequence of words are not the same so add padding and maximum length should be 50\nX_train = pad_sequences(X_train,padding='post',maxlen=50)\nX_test = pad_sequences(X_test,padding='post',maxlen=50)","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:46.566376Z","iopub.execute_input":"2024-08-18T18:37:46.566796Z","iopub.status.idle":"2024-08-18T18:37:46.970011Z","shell.execute_reply.started":"2024-08-18T18:37:46.566764Z","shell.execute_reply":"2024-08-18T18:37:46.968912Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"X_train[0]","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:49.292601Z","iopub.execute_input":"2024-08-18T18:37:49.292960Z","iopub.status.idle":"2024-08-18T18:37:49.300156Z","shell.execute_reply.started":"2024-08-18T18:37:49.292933Z","shell.execute_reply":"2024-08-18T18:37:49.299016Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"array([2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,\n         21,  134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,\n         36,   28,  224,   92,   25,  104,    4,  226,   65,   16,   38,\n       1334,   88,   12,   16,  283,    5,   16, 4472,  113,  103,   32,\n         15,   16, 5345,   19,  178,   32], dtype=int32)"},"metadata":{}}]},{"cell_type":"code","source":"# now create the RNN model\nmodel = Sequential()\n\n# Add an Input layer to define the input shape\nmodel.add(Input(shape=(50, 1)))\n\n# Add the SimpleRNN layer, return_seq = False because we need the output at the end and first time output should be part of all steps\n# such as t1 output = o1 and for t2 the input includes the o1 etc, same theory concept\nmodel.add(SimpleRNN(32, return_sequences=False))\n\n# Add the Dense output layer\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Print the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:37:54.024267Z","iopub.execute_input":"2024-08-18T18:37:54.024638Z","iopub.status.idle":"2024-08-18T18:37:54.076743Z","shell.execute_reply.started":"2024-08-18T18:37:54.024611Z","shell.execute_reply":"2024-08-18T18:37:54.075731Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,088\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,121\u001b[0m (4.38 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,121</span> (4.38 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,121\u001b[0m (4.38 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,121</span> (4.38 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nmodel.fit(X_train,y_train,epochs=5,validation_data=(X_test,y_test))","metadata":{"execution":{"iopub.status.busy":"2024-08-18T18:38:18.429585Z","iopub.execute_input":"2024-08-18T18:38:18.430006Z","iopub.status.idle":"2024-08-18T18:39:05.974521Z","shell.execute_reply.started":"2024-08-18T18:38:18.429960Z","shell.execute_reply":"2024-08-18T18:39:05.973267Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.4931 - loss: 0.7550 - val_accuracy: 0.5037 - val_loss: 0.6936\nEpoch 2/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5068 - loss: 0.6930 - val_accuracy: 0.5056 - val_loss: 0.6935\nEpoch 3/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5124 - loss: 0.6925 - val_accuracy: 0.5070 - val_loss: 0.6944\nEpoch 4/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5116 - loss: 0.6927 - val_accuracy: 0.5049 - val_loss: 0.6937\nEpoch 5/5\n\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.5025 - loss: 0.6928 - val_accuracy: 0.5048 - val_loss: 0.6943\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ab6384e8fa0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}